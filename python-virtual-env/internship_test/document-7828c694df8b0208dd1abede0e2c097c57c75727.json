{
   "url": "https://www.sony.net/SonyInfo/News/Press/202002/20-0219E/index.html",
   "title-of-article": "Sony and Prophesee Develop a Stacked Event-Based Vision Sensor with the Industry\u2019s Smallest Pixels and Highest HDR Performance",
   "time-stamp": 1593097155.336642,
   "content": "The press releases on this website are provided for historical reference purposes only. Please note that certain information may have changed since the date of release.\n\u2022 None Among stacked event-based vision sensors, as of announcement on February 19, 2020.\n\nTokyo, Japan\u2014Sony Corporation and Prophesee S.A. today announced they have jointly developed a stacked event-based vision sensor with the industry's smallest*1 4.86\u03bcm pixel size and the industry's highest*1 124dB (or more) HDR performance. The new sensor and its performance results were announced at the International Solid-State Circuits Conference (ISSCC) held in San Francisco in the United States, starting on February 16, 2020.\n\nThe new stacked event-based vision sensor detects changes in the luminance of each pixel asynchronously and outputs data including coordinates and time only for the pixels where a change is detected, thereby enabling high efficiency, high speed, low latency data output. This vision sensor achieves high resolution, high speed, and high time resolution despite its small size and low power consumption. This accomplishment was made possible by combining technical features of Sony's stacked CMOS image sensor, resulting in small pixel size and excellent low light performance that are achieved by the use of Cu-Cu connection*2, with Prophesee's Metavision\u00ae event-based vision sensing technologies leading to fast pixel response, high temporal resolution and high throughput data readout. The newly developed sensor is suitable for various machine vision applications, such as detecting fast moving objects in a wide range of environments and conditions.\n\u2022 None Technology that provides electrical continuity via connected Cu (copper) pads when stacking the back-illuminated CMOS image sensor section (top chip) and logic circuits (bottom chip). Compared with through-silicon via (TSV) wiring, where the connection is achieved by penetrating electrodes around the circumference of the pixel area, this method gives more freedom in design, improves productivity, allows for a more compact size, and increases performance. Sony announced this technology in December 2016 at the International Electron Devices Meeting (IEDM) in San Francisco.\n\u2022 Small size and high resolution delivered by stacked event-based vision sensor with the industry's smallest 4.86\u03bcm pixel size The pixel chip (top) and the logic chip (bottom) incorporate signal processing circuits which detect changes in luminance based on an asynchronous delta modulation method are arrayed separately. Each pixel of the two individual chips is electrically connected using Cu-Cu connection in a stacked configuration. In addition to the industry's smallest 4.86\u03bcm pixel size, the sensor also delivers 1/2 type, 1280x720 HD resolution by achieving high density integration with a fine 40nm logic process.\n\u2022 Industry's highest 124dB (or more) HDR performance achieved by high aperture ratio The industry's highest 124dB (or more) HDR performance is made possible by placing only back-illuminated pixels and a part of N-type MOS transistor on the pixel chip (top), thereby allowing the aperture ratio to be enhanced by up to 77%. High sensitivity/low noise technologies Sony has developed over many years of CMOS image sensor development enable event detection in low-light conditions (40mlx).\n\u2022 None Ratio of the aperture (other than the light-shielding portion) as viewed from the light incident surface side per pixel.\n\nWhile a frame-based sensor outputs entire images at fixed intervals according to the frame rate, an event-based sensor selects pixel data asynchronously using a row selection arbiter circuit*4. By adding time information at 1\u03bcs precision to the pixel address where a change in luminance has occurred, event data readout with high time resolution is ensured. Furthermore, a high output event rate of 1.066Geps*5 has been achieved by efficiently compressing the event data, i.e. luminance change polarity, time, and x/y coordinate information for each event.\n\u2022 None A circuit that determines the priority in the Y-axis direction corresponding to the requests from a plurality of pixels where a change in luminance has occurred.\n\u2022 None The number of events per second.\n\nProphesee develops the world's most advanced neuromorphic vision systems. The company's Event-Based approach to machine vision allows for significant reductions of power, latency and data processing requirements as compared to traditional frame-based vision systems.\n\n Prophesee's sensors and algorithms are designed to mimic the way biological eyes and brains work - with the goal to significantly improve performance, power and data efficiency of artificial vision systems in areas such as autonomous vehicles, industrial automation, IoT, security and surveillance, and AR/VR."
}